{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내가 낸 손은 가위일까, 바위일까, 보일까?\n",
    "## 부제 : 일단 딥러닝 네트워크를 만들어 봅시다.\n",
    "이번 시간에는 가위 바위 보 이미지를 학습시키는 네트워크를 짜보았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_data(img_path,img_num):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=img_num   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    #이미지를 차례대로 읽어들이면 오버피팅이 심할것 같아서 이미지를 일단 한 폴더채로 읽고, 그 안에서 이미지를 셔플했다. \n",
    "    idx=0\n",
    "    tmp_idx=idx\n",
    "    tmp_imgs=np.zeros(int(number_of_data/3)*img_size*img_size*color,dtype=np.int32).reshape(int(number_of_data/3),img_size,img_size,color)\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        tmp_imgs[tmp_idx,:,:,:]=img\n",
    "        labels[tmp_idx]=0\n",
    "        tmp_idx+=1\n",
    "        \n",
    "    np.random.shuffle(tmp_imgs)\n",
    "    \n",
    "    for ti in tmp_imgs:\n",
    "        imgs[idx,:,:,:]=ti\n",
    "        idx+=1\n",
    "\n",
    "    tmp_imgs=np.zeros(int(number_of_data/3)*img_size*img_size*color,dtype=np.int32).reshape(int(number_of_data/3),img_size,img_size,color)\n",
    "    tmp_idx=0\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        tmp_imgs[tmp_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        tmp_idx=tmp_idx+1\n",
    "        idx+=1\n",
    "      \n",
    "    np.random.shuffle(tmp_imgs)\n",
    "    \n",
    "    idx=idx-tmp_idx\n",
    "    for ti in tmp_imgs:\n",
    "        imgs[idx,:,:,:]=ti\n",
    "        idx+=1\n",
    "        \n",
    "    tmp_imgs=np.zeros(int(number_of_data/3)*img_size*img_size*color,dtype=np.int32).reshape(int(number_of_data/3),img_size,img_size,color)\n",
    "    tmp_idx=0\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        tmp_imgs[tmp_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        tmp_idx+=1\n",
    "    \n",
    "    np.random.shuffle(tmp_imgs)\n",
    "    \n",
    "    idx=idx-tmp_idx\n",
    "    for ti in tmp_imgs:\n",
    "        imgs[idx,:,:,:]=ti\n",
    "        idx+=1\n",
    "    \n",
    "        \n",
    "    print(\"읽어들인 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "#이미지가 리사이즈 되어서 들어온게 아니라면 리사이즈할 함수를 만들었다. \n",
    "def resize_data(img_dir_path):\n",
    "    images=glob.glob(img_dir_path + \"/*.jpg\")\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "읽어들인 이미지 개수는 6300 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 이미지의 숫자는 바로  0 입니다.\n",
      "읽어들인 이미지 개수는 900 입니다.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/Downloads/merged/\"\n",
    "training_data_num=6300\n",
    "(x_train, y_train)=load_data(image_dir_path,training_data_num)\n",
    "\n",
    "#렌덤으로 데이터가 섞였는지 확인해보려고 0번 이미지를 확인했다. 코드를 실행할 때 마다 다른 이미지가 보이는 것을 볼 수 있었다. \n",
    "index=0\n",
    "plt.imshow(x_train[index],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print( (index+1), '번째 이미지의 숫자는 바로 ',  y_train[index], '입니다.')\n",
    "\n",
    "# RGB값으로 표현되어있는 값을 정규화\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# validation set을 만들었는데, 학습 데이터의 20퍼센트를 validation에 사용했다. \n",
    "x_val = x_train_norm[-int(training_data_num/20):]\n",
    "y_val = y_train[-int(training_data_num/20):]\n",
    "\n",
    "x_train = x_train_norm[:-int(training_data_num/20)]\n",
    "y_train = y_train[:-int(training_data_num/20)]\n",
    "\n",
    "# 테스트 데이터 로딩\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Downloads/김찬호/rock_scissor_paper/\"\n",
    "test_data_num=900\n",
    "(x_test, y_test) = load_data(image_dir_path,test_data_num) \n",
    "x_test_norm = x_test/255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 310,723\n",
      "Trainable params: 310,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1005 - accuracy: 0.3143 - val_loss: 1.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0956 - accuracy: 0.3587 - val_loss: 1.2463 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0950 - accuracy: 0.3761 - val_loss: 1.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0934 - accuracy: 0.3873 - val_loss: 1.1868 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0918 - accuracy: 0.3993 - val_loss: 1.1971 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0898 - accuracy: 0.4075 - val_loss: 1.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0879 - accuracy: 0.4067 - val_loss: 1.2282 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0840 - accuracy: 0.4231 - val_loss: 1.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0786 - accuracy: 0.4236 - val_loss: 1.2276 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0738 - accuracy: 0.4175 - val_loss: 1.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0645 - accuracy: 0.4441 - val_loss: 1.2862 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0583 - accuracy: 0.4206 - val_loss: 1.1478 - val_accuracy: 0.0286\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0565 - accuracy: 0.4419 - val_loss: 1.1928 - val_accuracy: 0.0254\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0374 - accuracy: 0.4441 - val_loss: 1.3345 - val_accuracy: 0.0032\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0411 - accuracy: 0.4150 - val_loss: 1.1048 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0355 - accuracy: 0.4765 - val_loss: 1.0890 - val_accuracy: 0.2190\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0217 - accuracy: 0.5081 - val_loss: 1.3112 - val_accuracy: 0.0317\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0187 - accuracy: 0.4444 - val_loss: 1.1807 - val_accuracy: 0.1968\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9911 - accuracy: 0.5143 - val_loss: 1.0577 - val_accuracy: 0.3302\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9952 - accuracy: 0.5342 - val_loss: 1.1697 - val_accuracy: 0.2159\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9708 - accuracy: 0.5375 - val_loss: 1.2770 - val_accuracy: 0.1873\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9755 - accuracy: 0.5104 - val_loss: 0.8907 - val_accuracy: 0.7873\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9848 - accuracy: 0.5303 - val_loss: 1.0507 - val_accuracy: 0.4286\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9440 - accuracy: 0.5758 - val_loss: 1.5314 - val_accuracy: 0.0762\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9852 - accuracy: 0.4944 - val_loss: 0.9411 - val_accuracy: 0.6349\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9194 - accuracy: 0.6072 - val_loss: 0.8365 - val_accuracy: 0.7937\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9381 - accuracy: 0.5694 - val_loss: 1.1300 - val_accuracy: 0.3873\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8872 - accuracy: 0.6048 - val_loss: 1.3877 - val_accuracy: 0.1619\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9205 - accuracy: 0.5474 - val_loss: 0.9720 - val_accuracy: 0.5556\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8845 - accuracy: 0.6195 - val_loss: 0.7573 - val_accuracy: 0.8317\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8888 - accuracy: 0.5942 - val_loss: 1.0897 - val_accuracy: 0.4508\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8545 - accuracy: 0.6190 - val_loss: 1.3053 - val_accuracy: 0.2063\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8544 - accuracy: 0.6030 - val_loss: 0.8867 - val_accuracy: 0.6381\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8159 - accuracy: 0.6680 - val_loss: 0.7646 - val_accuracy: 0.7365\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8307 - accuracy: 0.6144 - val_loss: 0.9960 - val_accuracy: 0.5270\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7830 - accuracy: 0.6725 - val_loss: 1.1939 - val_accuracy: 0.2794\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8012 - accuracy: 0.6361 - val_loss: 0.9811 - val_accuracy: 0.5810\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7760 - accuracy: 0.6615 - val_loss: 0.5224 - val_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8870 - accuracy: 0.5499 - val_loss: 1.3261 - val_accuracy: 0.3397\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8230 - accuracy: 0.6266 - val_loss: 1.2143 - val_accuracy: 0.2794\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7707 - accuracy: 0.6454 - val_loss: 0.8222 - val_accuracy: 0.6730\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7466 - accuracy: 0.6986 - val_loss: 0.7638 - val_accuracy: 0.7079\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7542 - accuracy: 0.6678 - val_loss: 0.8409 - val_accuracy: 0.6540\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7460 - accuracy: 0.6901 - val_loss: 0.8716 - val_accuracy: 0.6413\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7136 - accuracy: 0.7233 - val_loss: 1.0276 - val_accuracy: 0.4857\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7232 - accuracy: 0.6924 - val_loss: 1.0128 - val_accuracy: 0.5429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6947 - accuracy: 0.7253 - val_loss: 0.6912 - val_accuracy: 0.7429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6919 - accuracy: 0.7088 - val_loss: 0.6651 - val_accuracy: 0.7619\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6776 - accuracy: 0.7158 - val_loss: 1.0970 - val_accuracy: 0.5079\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6668 - accuracy: 0.7320 - val_loss: 0.9812 - val_accuracy: 0.5651\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6579 - accuracy: 0.7312 - val_loss: 0.6790 - val_accuracy: 0.7397\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6379 - accuracy: 0.7395 - val_loss: 0.7585 - val_accuracy: 0.6921\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6404 - accuracy: 0.7373 - val_loss: 0.7423 - val_accuracy: 0.7048\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6208 - accuracy: 0.7557 - val_loss: 1.0058 - val_accuracy: 0.5587\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6196 - accuracy: 0.7527 - val_loss: 0.7176 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5961 - accuracy: 0.7691 - val_loss: 0.6047 - val_accuracy: 0.7683\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5928 - accuracy: 0.7587 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5707 - accuracy: 0.7851 - val_loss: 0.7721 - val_accuracy: 0.6825\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5911 - accuracy: 0.7642 - val_loss: 0.9546 - val_accuracy: 0.6159\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5941 - accuracy: 0.7769 - val_loss: 0.3875 - val_accuracy: 0.8508\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6474 - accuracy: 0.7031 - val_loss: 1.1752 - val_accuracy: 0.4952\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6134 - accuracy: 0.7542 - val_loss: 0.9374 - val_accuracy: 0.6032\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5619 - accuracy: 0.7783 - val_loss: 0.4738 - val_accuracy: 0.8222\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5666 - accuracy: 0.7681 - val_loss: 0.6391 - val_accuracy: 0.7429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5471 - accuracy: 0.7813 - val_loss: 0.7556 - val_accuracy: 0.6952\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5124 - accuracy: 0.8110 - val_loss: 0.7655 - val_accuracy: 0.6698\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5387 - accuracy: 0.7910 - val_loss: 0.6560 - val_accuracy: 0.7365\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4919 - accuracy: 0.8175 - val_loss: 0.6103 - val_accuracy: 0.7619\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5175 - accuracy: 0.7933 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4929 - accuracy: 0.8075 - val_loss: 0.9205 - val_accuracy: 0.6254\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5022 - accuracy: 0.7992 - val_loss: 0.7640 - val_accuracy: 0.6984\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4647 - accuracy: 0.8212 - val_loss: 0.3688 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5117 - accuracy: 0.7791 - val_loss: 0.7935 - val_accuracy: 0.6857\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4739 - accuracy: 0.8206 - val_loss: 0.7677 - val_accuracy: 0.6730\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4679 - accuracy: 0.8201 - val_loss: 0.5180 - val_accuracy: 0.7905\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4547 - accuracy: 0.8277 - val_loss: 0.5698 - val_accuracy: 0.7619\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4765 - accuracy: 0.8142 - val_loss: 0.4965 - val_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4190 - accuracy: 0.8449 - val_loss: 0.6998 - val_accuracy: 0.7143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4375 - accuracy: 0.8324 - val_loss: 0.7338 - val_accuracy: 0.7016\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4285 - accuracy: 0.8378 - val_loss: 0.4225 - val_accuracy: 0.8286\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4179 - accuracy: 0.8386 - val_loss: 0.5015 - val_accuracy: 0.8032\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4001 - accuracy: 0.8513 - val_loss: 0.7023 - val_accuracy: 0.7238\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4110 - accuracy: 0.8459 - val_loss: 0.5952 - val_accuracy: 0.7460\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3924 - accuracy: 0.8531 - val_loss: 0.4161 - val_accuracy: 0.8254\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3914 - accuracy: 0.8481 - val_loss: 0.5276 - val_accuracy: 0.7873\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3792 - accuracy: 0.8620 - val_loss: 0.5512 - val_accuracy: 0.7587\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3765 - accuracy: 0.8617 - val_loss: 0.5743 - val_accuracy: 0.7619\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3570 - accuracy: 0.8703 - val_loss: 0.4107 - val_accuracy: 0.8286\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3645 - accuracy: 0.8602 - val_loss: 0.4675 - val_accuracy: 0.8032\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3519 - accuracy: 0.8657 - val_loss: 0.6442 - val_accuracy: 0.7302\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3569 - accuracy: 0.8655 - val_loss: 0.4021 - val_accuracy: 0.8190\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3435 - accuracy: 0.8670 - val_loss: 0.4679 - val_accuracy: 0.8032\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3478 - accuracy: 0.8660 - val_loss: 0.4537 - val_accuracy: 0.8032\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3352 - accuracy: 0.8705 - val_loss: 0.5796 - val_accuracy: 0.7492\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3270 - accuracy: 0.8840 - val_loss: 0.3535 - val_accuracy: 0.8540\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3208 - accuracy: 0.8795 - val_loss: 0.4707 - val_accuracy: 0.8063\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3142 - accuracy: 0.8871 - val_loss: 0.4252 - val_accuracy: 0.8190\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3056 - accuracy: 0.8904 - val_loss: 0.4561 - val_accuracy: 0.8127\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3010 - accuracy: 0.8901 - val_loss: 0.3357 - val_accuracy: 0.8635\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3034 - accuracy: 0.8879 - val_loss: 0.6290 - val_accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "# n_channel은 해당 데이터에서 얼마나 특징을 잡아내는지를 결정하는 척도라고 했다. \n",
    "# 그래서 처음에는 대강 분류하고, 그 후에 좀 더 값을 높여 학습시켰다. \n",
    "n_channel_1=64\n",
    "n_channel_2=128\n",
    "# 해당 값은 neural network의 layer 층 갯수라고 해서 다양한 이미지에 대응하기 위해 값을 높였다. \n",
    "n_dense=512\n",
    "# 학습 횟수\n",
    "n_train_epoch=100\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "# 오버피팅을 막기 위해 각 학습 단계마다 제대로 학습한 데이터를 드랍시킨다. 그 비율을 0.5로 잡았다. 대신 학습 횟수를 엄청 늘렸다. \n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "training_data_size = x_train.size\n",
    "\n",
    "# 모델 훈련\n",
    "# batch_size를 정해준 이유는 한번 학습할 때 전체 데이터를 다 쓰지 않도록 막으려고 정했다. 오버피팅을 막으려고. \n",
    "training_result=model.fit(x_train, y_train, batch_size=int(training_data_size/50), epochs=n_train_epoch,validation_data=(x_val,y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 모델은 11개의 레이어를 가지게 되었다. 오버피팅을 막아보려고 시도한 여러가지 일 중 하나다.   \n",
    "1. 레이어 수 늘리기\n",
    "   레이어 수를 늘리면 좀 더 정교해질 줄 알았다. 그래서 늘려봤다. Dropout을 추가하면 오버피팅을 막을 수 있다고 해서 추가했다. 20퍼센트의 제대로 추론한 케이스들을 드랍시킨다는 의미. \n",
    "2. hyper-parameter 조정하기\n",
    "    - n_channel : 얼마 정도 데이터의 특성을 고려할 것인가? 에 대한 값이라고 들어서 늘려도 보고 줄여도 봤는데 작게는 32, 크게는 512까지 줘봤는데 역시 생각해보니까 데이터가 28*28로 리사이즈되면서 많이 뭉뚱그려지는 영향이 있기에 큰 수는 오히려 오버피팅을 유도하는 것 같았다. 그래서 실험적으로 얻어낸 값이 처음에는 32, 다음 레이어에서는 2배인 64, 그 다음은 2배를 해서 128을 주게 되었다. \n",
    "    - n_dense : 정교한 모델을 얻기 위해 뉴럴 네트워크 내의 레이어들을 늘리게 되었다. 하얀 배경에 가위, 바위, 보만 찍히면 가장 좋은 데이터이지만 주변 배경이 나오게 찍힌 경우가 있어서 모델이 정교할 필요가 있었다. \n",
    "    - n_epoch : 위의 값들이 매우 큰 값이기 때문에 충분한 학습의 반복이 필요하다고 여겨 100을 줬다.\n",
    "    - batch_size : 무식하게 실험 수만 늘리면 이것도 학습 데이터에 오버피팅이 되기 때문에 매 학습마다 데이터의 일부만 쓰도록 했다. \n",
    "3. 데이터 수 늘리기\n",
    "    여기서 고생을 했는데, 사실 내 문제는 학습 데이터를 무지막하게 늘릴 생각만 했지, 이 모델이 제대로 작동하도록 판을 깔아주는 일을 하지 않았다는 것이 결정적인 삽질의 시작이었다. 6300개까지 학습시키면 뭐하나, 테스트 데이터가 300개면 모델이 기지개 켜기도 전에 테스트가 종료될 것이다. 아. 허무해라. 그래서 세 배로 데이터를 늘리니까 바로 정확도가 확 올라갔다. \n",
    "4. Validation 추가\n",
    "    데이터가 제대로 학습되었는지 계속 확인하고 싶어서 validation 단계를 넣어서 모니터링했다. 학습 횟수를 100으로 준 이유가 validation이 학습 결과와 수렴하려면 그 정도의 횟수가 필요하더라...\n",
    "5. 데이터 무작위로 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 0.7099 - accuracy: 0.7389\n",
      "test_loss: 0.7099137902259827 \n",
      "test_accuracy: 0.7388888597488403\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###회고\n",
    "오버피팅을 피하기 위해서 오만 짓을 다 해봤는데, 그거 때문에 모델을 200번 정도는 돌린것 같다(중간에 커널 접속이 끊겨서 실행 횟수 초기화).\n",
    "어떻게든 데이터가 편향되지 않게(이를 위해 데이터를 셔플했다.), 한번에 전부 다 쓰이지 않게 조절하는 것에 집중했다. 설마 실행횟수를 100번까지 늘릴 생각까지 못했는데, batch_size를 정해주게 되면서 실험 횟수를 늘릴 수 밖에 없었다. 그래. 일은 내가 하는게 아니라 컴퓨터가 하지. 그러면서 의외의 하이퍼파라미터를 알게 되었다. 그리고 테스트 데이터도 같이 규모를 키워야 한다는걸 몰라서 학습 데이터 수 늘리기에만 집착했는데 아무리 해도 테스트 데이터에서 좋게 봐줘야 0.54까지만 올라가는 것을 보고 크게 좌절했다. 근데 데이터를 더해주니까 쭉쭉 정확도가 올라가서 너무 당황했다. 데이터 규모는 학습이나 테스트나 둘 다 중요하다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
