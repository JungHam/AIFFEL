{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from scikit-learn) (1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (2020.12.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: six in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 패키지가 없다면 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(150, 4)\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     label  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "..     ...  \n",
      "145      2  \n",
      "146      2  \n",
      "147      2  \n",
      "148      2  \n",
      "149      2  \n",
      "\n",
      "[150 rows x 5 columns]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "X_train 개수:  120 , X_test 개수:  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "\n",
    "print(type(dir(iris))) \n",
    "iris.keys()\n",
    "\n",
    "iris_data = iris.data\n",
    "\n",
    "print(iris_data.shape) \n",
    "\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df[\"label\"]=iris.target\n",
    "iris_df\n",
    "iris_label = iris.target\n",
    "print(iris_df)\n",
    "print(iris.target_names)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#데이터, 데이터 라벨, 테스트에 쓰이는 데이터의 비율, 렌덤으로 데이터를 고르는 정도\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iris 데이터셋을 로드하고, pandas 라이브러리를 사용해서 데이터의 특성에 대해 알아보며, train_test_split 라이브러리를 통해 테스트데이터를 준비한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-55-cf166d175fbc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-cf166d175fbc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    처음으로 모델을 써봤다. Decision Tree를 이용해서 학습시키고 결과를 accuracy score, 그러니까 `(올바르게 맞춘 갯수)/(전체 데이터 갯수)` 로 판단한다.\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "처음으로 모델을 써봤다. Decision Tree를 이용해서 학습시키고 결과를 accuracy score, 그러니까 `(올바르게 맞춘 갯수)/(전체 데이터 갯수)` 로 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=25)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 Random Forest를 이용해 학습해 보고, classification_report 함수를 통해 오차행렬을 출력했다. 데이터의 경우에 따라 precision을 선택하던, recall을 선택하던, f1-score를 선택하던 의미가 각각 다르지만, 이 데이터에서는 딱히 라벨을 조작하지 않았기 때문에 precision과 recall의 조화평균인 f1-score를 평가의 지표로 삼으려고 한다. 조화평균의 경우 setosa 종에 대해서 잘 분류하는 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn에서 제공하는 데이터셋 로드하기\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#필요한 모델들을 한꺼번에 로드했다.\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 시험삼아서 0-9 사이의 숫자를 손으로 쓴 글씨를 분류하려고 한다. 이를 토대로 함수를 만들어서 한번에 여러 모델을 학습시키려고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "<Decision Tree>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "<Random Forest>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "<SVM>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "<SGD>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.87      0.93      0.90        42\n",
      "           2       0.97      0.95      0.96        40\n",
      "           3       0.94      0.94      0.94        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.90      1.00      0.95        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.90      0.88      0.89        43\n",
      "           9       0.93      0.88      0.90        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "<logistic>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#숫자 데이터 업로드 및 구성 알아보기\n",
    "digits = load_digits()\n",
    "digits.keys()\n",
    "\n",
    "digits_data = digits.data\n",
    "digits_data.shape\n",
    "\n",
    "#예시 데이터 하나 출력하기\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]\n",
    "\n",
    "#학습과 테스트 데이터 생성하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "#의사결정트리로 학습시키고 결과 보기\n",
    "print(\"<Decision Tree>\")\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "#렌덤포레스트로 학습시키고 결과 보기\n",
    "print(\"<Random Forest>\")\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "#svm으로 학습시키고 결과 보기\n",
    "print(\"<SVM>\")\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "#SGD로 학습시키고 결과 보기\n",
    "print(\"<SGD>\")\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)\n",
    "\n",
    "#logistic으로 학습시키고 결과 보기\n",
    "print(\"<logistic>\")\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train,y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "result = classification_report(y_test,y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 분류기의 경우 맞다 틀리다가 중요하기 때문에(숫자 분류기가 우편번호 인식에 주로 쓰이는 것으로 알고 있음), recall보다는 precision이 더 적합하다고 본다.   \n",
    "학습 결과를 accuracy의 macro avg로 평가하면 의사결정트리가 0.86, 렌덤포레스트가 0.96, SVM이 0.99, SGD가 0.95, logistic이 0.95로 SVM에서 가장 좋은 예측 결과를 보여주었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_with_different_classifier_models(test_data, test_size):\n",
    "    #데이터 받아서 라벨과 클래스 이름 추출하기\n",
    "    target_data = test_data.data\n",
    "    target_label = test_data.target\n",
    "    target_label_name = test_data.target_names\n",
    "    #데이터 구조를 출력하기\n",
    "    data_df = pd.DataFrame(data=target_data, columns=test_data.feature_names)\n",
    "    data_df[\"label\"]=target_label\n",
    "    print(\"data set describe\")\n",
    "    print(data_df)\n",
    "    print(\"data set shape\")\n",
    "    print(target_data.shape)\n",
    "    print(\"data label shape\")\n",
    "    print(target_label.shape)\n",
    "    print(\"class name\")\n",
    "    print(target_label_name)\n",
    "    \n",
    "    #학습과 테스트 데이터 생성하기\n",
    "    X_train, X_test, y_train, y_test = train_test_split(target_data,\n",
    "                                                    target_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "    \n",
    "    #Decision Tree로 학습하기\n",
    "    print(\"learning with Decision tree\")\n",
    "    decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    #오차행렬 출력하기\n",
    "    model_result = classification_report(y_test,y_pred)\n",
    "    print(model_result)\n",
    "    \n",
    "    #Random Forest로 학습하기\n",
    "    print(\"learning with Random forest\")\n",
    "    random_forest = RandomForestClassifier(random_state=32)\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(accuracy)\n",
    "    model_result = classification_report(y_test,y_pred)\n",
    "    print(model_result)\n",
    "    \n",
    "    #SVM으로 학습하기\n",
    "    print(\"learning with SVM\")\n",
    "    svm_model = svm.SVC()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_result = classification_report(y_test,y_pred)\n",
    "    print(model_result)\n",
    "    \n",
    "    #SGD로 학습하기\n",
    "    print(\"learning with SGD\")\n",
    "    sgd_model = SGDClassifier()\n",
    "    sgd_model.fit(X_train, y_train)\n",
    "    y_pred = sgd_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_result = classification_report(y_test,y_pred)\n",
    "    print(model_result)\n",
    "\n",
    "    #Logistic model로 학습하기\n",
    "    print(\"learning with logistic model\")\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(X_train,y_train)\n",
    "    y_pred = logistic_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_result = classification_report(y_test,y_pred)\n",
    "    print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<digits>\n",
      "data set describe\n",
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
      "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
      "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
      "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
      "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
      "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
      "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
      "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
      "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
      "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
      "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
      "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
      "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
      "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
      "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
      "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
      "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
      "\n",
      "      pixel_7_7  label  \n",
      "0           0.0      0  \n",
      "1           0.0      1  \n",
      "2           0.0      2  \n",
      "3           0.0      3  \n",
      "4           0.0      4  \n",
      "...         ...    ...  \n",
      "1792        0.0      9  \n",
      "1793        0.0      0  \n",
      "1794        0.0      8  \n",
      "1795        0.0      9  \n",
      "1796        0.0      8  \n",
      "\n",
      "[1797 rows x 65 columns]\n",
      "data set shape\n",
      "(1797, 64)\n",
      "data label shape\n",
      "(1797,)\n",
      "class name\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "learning with Decision tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "learning with Random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "learning with SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "learning with SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.78      1.00      0.88        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.97      0.88      0.92        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.88      1.00      0.93        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.97      0.79      0.87        43\n",
      "           9       1.00      0.88      0.93        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n",
      "learning with logistic model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "<wine>\n",
      "data set describe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  label  \n",
      "0                            3.92   1065.0      0  \n",
      "1                            3.40   1050.0      0  \n",
      "2                            3.17   1185.0      0  \n",
      "3                            3.45   1480.0      0  \n",
      "4                            2.93    735.0      0  \n",
      "..                            ...      ...    ...  \n",
      "173                          1.74    740.0      2  \n",
      "174                          1.56    750.0      2  \n",
      "175                          1.56    835.0      2  \n",
      "176                          1.62    840.0      2  \n",
      "177                          1.60    560.0      2  \n",
      "\n",
      "[178 rows x 14 columns]\n",
      "data set shape\n",
      "(178, 13)\n",
      "data label shape\n",
      "(178,)\n",
      "class name\n",
      "['class_0' 'class_1' 'class_2']\n",
      "learning with Decision tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "learning with Random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "learning with SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "learning with SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44         7\n",
      "           1       0.80      0.24      0.36        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.31        36\n",
      "   macro avg       0.36      0.41      0.27        36\n",
      "weighted avg       0.43      0.31      0.26        36\n",
      "\n",
      "learning with logistic model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "<breast cancer>\n",
      "data set describe\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
      "0                  0.2654          0.4601                  0.11890      0  \n",
      "1                  0.1860          0.2750                  0.08902      0  \n",
      "2                  0.2430          0.3613                  0.08758      0  \n",
      "3                  0.2575          0.6638                  0.17300      0  \n",
      "4                  0.1625          0.2364                  0.07678      0  \n",
      "..                    ...             ...                      ...    ...  \n",
      "564                0.2216          0.2060                  0.07115      0  \n",
      "565                0.1628          0.2572                  0.06637      0  \n",
      "566                0.1418          0.2218                  0.07820      0  \n",
      "567                0.2650          0.4087                  0.12400      0  \n",
      "568                0.0000          0.2871                  0.07039      1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "data set shape\n",
      "(569, 30)\n",
      "data label shape\n",
      "(569,)\n",
      "class name\n",
      "['malignant' 'benign']\n",
      "learning with Decision tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "learning with Random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "learning with SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "learning with SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "learning with logistic model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "print(\"<digits>\")\n",
    "play_with_different_classifier_models(digits,0.2)\n",
    "print(\"<wine>\")\n",
    "play_with_different_classifier_models(load_wine(),0.2)\n",
    "print(\"<breast cancer>\")\n",
    "play_with_different_classifier_models(load_breast_cancer(),0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 분류기의 경우 위에서 서술하였으므로 와인과 유방암에 대해 평가지표를 서술하겠다.    \n",
    "##### 와인\n",
    "와인은 여러 속성들의 수치들을 통해 3가지의 와인 중 어느 와인인지 추론하는 문제이다.   \n",
    "그렇다면 각 모델의 특성을 간략히 언급하면서 어떤 모델이 좋은 결과를 낼 수 있는지 추론해 보자.    \n",
    "Decision tree -> tree의 각 단계에서 선택하는 속성의 순서에 따라 결과가 달라질 수 있다.   \n",
    "Random Forest -> Decision Tree의 이러한 단점을 극복하여, 각 단계마다 렌덤으로 속성이 정해지고, 트리를 여러번 반복하여 결과를 하나로 합친다.    \n",
    "SVM -> 여러 클래스를 분류할 때, 선형 분류가 어려워질 경우 초월차원을 통해 클래스를 분류한다.    \n",
    "SGD -> loss를 줄여나가면서 학습할 때, 이 loss에 피드백을 주면서 점차 줄이게 되는데 (gradient decent) 이 방법에는 여러가지 방법이 있고 그 중 하나가 SGD 방식.loss에 피드백을 줄 때 갑자기 값이 튀는 경우가 꽤 있다.\n",
    "( 참조 : https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/ )\n",
    "logistic regression -> 2가지 class가 있을때 예, 아니오를 파악하는 데에 유리하다.   \n",
    "\n",
    "속성들이 여러가지일때, 한 가지 속성으로 클래스가 결정된다면 다른 속성을 같이 넣고 돌리는 것은 차원의 저주를 일으키는 것 밖에 되지 않는다. 그래서 랜덤하게 속성을 선택해서 고려하는 모델들이 유리하지 않을까 생각을 했다. Random forest의 정확도가 모두 1로 가장 정확하게 나왔다. 전부 1이라고...? toy dataset이라서 그런가...?  \n",
    "\n",
    "\n",
    "##### 유방암\n",
    "유방암은 정확도 중 재현률이 높아야 한다. \n",
    "그래서 재현률이 높은 모델을 살펴보려고 한다. \n",
    "위의 와인과 같이 유방암 진단에도 여러 속성이 쓰인다. 그런데 어라? 여기서도 Random forest의 정확도가 모두 1로 가장 정확하게 나왔다. 대체 뭐지...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "여러가지 모델에 대해서 실험해 봤는데, 숫자 분류기가 클래스가 10개라서 svm이 초월차원에서 이들을 구분해내기 힘들 거라 생각했는데 가장 높은 결과가 나와서 놀랐고, 와인이랑 유방암 데이터는 Random forest에서 정확도 지표가 모두 1이 나와서 더욱 놀랐다. 실제 와인의 수치(이탈리아산이라고 나와있다.)와 환자의 검진 결과일 텐데 분류가 너무 잘 되는거 아닌가.   \n",
    "간단히 각 모델의 특성에 대해 알아봤는데 학부때 배웠던 이론보다 직접 해보니까 더 와닿긴 한데 학부때 배운건 정말 빙산의 일각에 요약 수준 밖에 되지 않는다는게 놀랍다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
